{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4862520,"sourceType":"datasetVersion","datasetId":2818963}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"About Dataset\nThis dataset is having the data of 1K+ Amazon Product's Ratings and Reviews as per their details listed on the official website of Amazon\n\nFeatures\n\nproduct_id - Product ID    \nproduct_name - Name of the Product  \ncategory - Category of the Product  \ndiscounted_price - Discounted Price of the Product   \nactual_price - Actual Price of the Product  \ndiscount_percentage - Percentage of Discount for the Product  \nrating - Rating of the Product  \nrating_count - Number of people who voted for the Amazon rating  \nabout_product - Description about the Product  \nuser_id - ID of the user who wrote review for the Product  \nuser_name - Name of the user who wrote review for the Product  \nreview_id - ID of the user review  \nreview_title - Short review  \nreview_content - Long review  \nimg_link - Image Link of the Product  \nproduct_link - Official Website Link of the Product  \n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:34:04.199052Z","iopub.execute_input":"2024-08-15T04:34:04.20003Z","iopub.status.idle":"2024-08-15T04:34:04.210982Z","shell.execute_reply.started":"2024-08-15T04:34:04.199971Z","shell.execute_reply":"2024-08-15T04:34:04.209259Z"}}},{"cell_type":"markdown","source":"In this workbook, I will perform the following tasks:\n\n1. Data Cleaning:\n   - Handle missing values\n   - Remove duplicates (if any)\n   - Correct data types\n   - Address any inconsistencies in the dataset\n\n2. Data Exploration:\n   - Analyze basic statistics of numerical columns\n   - Visualize distributions of key variables\n   - Identify patterns and trends in the data\n\n3. Answer Key Questions:\n   - Determine top-selling products\n   - Identify most popular product categories\n   - Explore the relationship between ratings and other variables\n\n4. Visualization:\n   - Create informative charts and graphs to illustrate findings\n\nThe goal is to gain insights into product performance, customer preferences, and pricing strategies to inform business decisions.","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:34:27.484855Z","iopub.execute_input":"2024-08-15T04:34:27.486259Z","iopub.status.idle":"2024-08-15T04:34:27.494306Z","shell.execute_reply.started":"2024-08-15T04:34:27.486215Z","shell.execute_reply":"2024-08-15T04:34:27.492642Z"}}},{"cell_type":"markdown","source":"Imported Libraries:  \n    Numpy  \n    Pandas  \n    Seaborn  \n    Matplotlib.pyplot\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:40:07.338667Z","iopub.execute_input":"2024-08-15T04:40:07.339146Z","iopub.status.idle":"2024-08-15T04:40:07.347054Z","shell.execute_reply.started":"2024-08-15T04:40:07.339108Z","shell.execute_reply":"2024-08-15T04:40:07.345429Z"}}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:40:24.322391Z","iopub.execute_input":"2024-08-15T04:40:24.322898Z","iopub.status.idle":"2024-08-15T04:40:24.3305Z","shell.execute_reply.started":"2024-08-15T04:40:24.322859Z","shell.execute_reply":"2024-08-15T04:40:24.328678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#importing the dtaa\ndf = pd.read_csv(\"/kaggle/input/amazon-sales-dataset/amazon.csv\")\ndf\n\n#good to have a look at the col values to get a better understanding of data ","metadata":{"execution":{"iopub.status.busy":"2024-08-15T04:40:26.879379Z","iopub.execute_input":"2024-08-15T04:40:26.879861Z","iopub.status.idle":"2024-08-15T04:40:27.029222Z","shell.execute_reply.started":"2024-08-15T04:40:26.879814Z","shell.execute_reply":"2024-08-15T04:40:27.027603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets have a look at data types, columns, row number\ndf.info()\n\n#all cols are object format, need to convert the numbers into numerical format","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:18:40.046923Z","iopub.execute_input":"2024-08-15T05:18:40.048336Z","iopub.status.idle":"2024-08-15T05:18:40.066783Z","shell.execute_reply.started":"2024-08-15T05:18:40.04829Z","shell.execute_reply":"2024-08-15T05:18:40.065218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['actual_price'] #need to remove the ₹ sign, also comma, so we'll be able to convert it into float\ndf['discounted_price']","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:19:58.010604Z","iopub.execute_input":"2024-08-15T05:19:58.011054Z","iopub.status.idle":"2024-08-15T05:19:58.021108Z","shell.execute_reply.started":"2024-08-15T05:19:58.011021Z","shell.execute_reply":"2024-08-15T05:19:58.019768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['actual_price']= df['actual_price'].replace( {'\\₹': '' , ',': ''}, regex=True).astype(float)\n\ndf['discounted_price']= df['discounted_price'].replace( {'\\₹': '' , ',': ''}, regex=True).astype(float)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:20:14.937729Z","iopub.execute_input":"2024-08-15T05:20:14.938226Z","iopub.status.idle":"2024-08-15T05:20:14.970662Z","shell.execute_reply.started":"2024-08-15T05:20:14.938189Z","shell.execute_reply":"2024-08-15T05:20:14.969301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:20:17.643234Z","iopub.execute_input":"2024-08-15T05:20:17.643705Z","iopub.status.idle":"2024-08-15T05:20:17.662802Z","shell.execute_reply.started":"2024-08-15T05:20:17.64367Z","shell.execute_reply":"2024-08-15T05:20:17.661553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['discount_percentage']  #need to remove the % sign, so we'll be able to convert it into float\n\ndf['discount_percentage']= df['discount_percentage'].replace( {'%': ''}, regex=True).astype(float)/100\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:23:02.558312Z","iopub.execute_input":"2024-08-15T05:23:02.55963Z","iopub.status.idle":"2024-08-15T05:23:02.585932Z","shell.execute_reply.started":"2024-08-15T05:23:02.55958Z","shell.execute_reply":"2024-08-15T05:23:02.5845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#how about rating col?\ndf['rating'] #sounds ok, lets have a look at all unique values in this col\n\nsorted(df['rating'].unique(), reverse=False)\n#rating is from 2 (min) to 5 (max) , and there a typo in there as | which needs to be removed or replaced","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:24:35.849991Z","iopub.execute_input":"2024-08-15T05:24:35.850441Z","iopub.status.idle":"2024-08-15T05:24:35.860716Z","shell.execute_reply.started":"2024-08-15T05:24:35.850408Z","shell.execute_reply":"2024-08-15T05:24:35.859381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets see the row with \\ as rating\ndf[df['rating']== '|']\n#do we have any other review for this product?\n#As my dataset is small I prefer to see if I can replace it with something rather than just removing rhe row","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:25:40.328777Z","iopub.execute_input":"2024-08-15T05:25:40.329407Z","iopub.status.idle":"2024-08-15T05:25:40.360095Z","shell.execute_reply.started":"2024-08-15T05:25:40.329368Z","shell.execute_reply":"2024-08-15T05:25:40.358737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#do we have any other review for this product?\ndf[df['product_id']== 'B08L12N5H1']\n#Nop! so i suggest to replace it with the AVG rating, also I had a look at review_content to see if it got good reviews or not","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:30:04.520913Z","iopub.execute_input":"2024-08-15T05:30:04.521631Z","iopub.status.idle":"2024-08-15T05:30:04.546484Z","shell.execute_reply.started":"2024-08-15T05:30:04.521587Z","shell.execute_reply":"2024-08-15T05:30:04.544965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['rating'] = pd.to_numeric(df['rating'], errors='coerce') #coerce helps to change non number to NA instead of getting an error\n\n#so now I have that as NA and I need to replace it with Mean\n\navg_rating = df['rating'].mean()\n\ndf['rating'] = df['rating'].fillna(avg_rating)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:31:55.480696Z","iopub.execute_input":"2024-08-15T05:31:55.481713Z","iopub.status.idle":"2024-08-15T05:31:55.49407Z","shell.execute_reply.started":"2024-08-15T05:31:55.481652Z","shell.execute_reply":"2024-08-15T05:31:55.492417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show me rows with null rating, also the format is float now\ndf[df['rating'].isnull()]","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:32:14.463962Z","iopub.execute_input":"2024-08-15T05:32:14.464943Z","iopub.status.idle":"2024-08-15T05:32:14.482339Z","shell.execute_reply.started":"2024-08-15T05:32:14.464899Z","shell.execute_reply":"2024-08-15T05:32:14.480528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:32:49.755324Z","iopub.execute_input":"2024-08-15T05:32:49.755787Z","iopub.status.idle":"2024-08-15T05:32:49.77369Z","shell.execute_reply.started":"2024-08-15T05:32:49.755752Z","shell.execute_reply":"2024-08-15T05:32:49.772209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets have a look at rating_count, we already know there are 2 null \ndf[df['rating_count'].isnull()]\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:33:14.73692Z","iopub.execute_input":"2024-08-15T05:33:14.737584Z","iopub.status.idle":"2024-08-15T05:33:14.7625Z","shell.execute_reply.started":"2024-08-15T05:33:14.737532Z","shell.execute_reply":"2024-08-15T05:33:14.7611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#let me see if we have duplicated for these 2 prods B0B94JPY2N , B0BQRJ3C47\n#df[df['product_id']=='B0BQRJ3C47']\n\ndf[df['product_id'].isin(['B0B94JPY2N', 'B0BQRJ3C47'])]\n#nop! we can delete these rows , or replace NA with 1 as there's at least one review here in the data, or replace them with avg(rating_count). ","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:34:20.041796Z","iopub.execute_input":"2024-08-15T05:34:20.042257Z","iopub.status.idle":"2024-08-15T05:34:20.069758Z","shell.execute_reply.started":"2024-08-15T05:34:20.042221Z","shell.execute_reply":"2024-08-15T05:34:20.068266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i think good to replace nan with 1 as these rows include at least one rating, also need to change the format\ndf['rating_count'] = df['rating_count'].fillna(1)\n\n#Also need to remove commas\ndf['rating_count'] = df['rating_count'].replace( { ',': ''}, regex=True).astype('float64')\n\ndf['rating_count']","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:44:22.193069Z","iopub.execute_input":"2024-08-15T05:44:22.193564Z","iopub.status.idle":"2024-08-15T05:44:22.215376Z","shell.execute_reply.started":"2024-08-15T05:44:22.193519Z","shell.execute_reply":"2024-08-15T05:44:22.214024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#the data format looks goo for all cols now\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:44:45.241485Z","iopub.execute_input":"2024-08-15T05:44:45.242975Z","iopub.status.idle":"2024-08-15T05:44:45.262866Z","shell.execute_reply.started":"2024-08-15T05:44:45.242919Z","shell.execute_reply":"2024-08-15T05:44:45.261308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Any other null values?\ndf.isnull().sum().sort_values(ascending = False)\n\n#Nop! Sounds great","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:45:00.096531Z","iopub.execute_input":"2024-08-15T05:45:00.097076Z","iopub.status.idle":"2024-08-15T05:45:00.114004Z","shell.execute_reply.started":"2024-08-15T05:45:00.097028Z","shell.execute_reply":"2024-08-15T05:45:00.112307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets have a look at a summary of numerical cols\ndf.describe()\n\n#I see in this dataset we have a wide variety of products with different price from 39 to 139900. ","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:47:59.375131Z","iopub.execute_input":"2024-08-15T05:47:59.375568Z","iopub.status.idle":"2024-08-15T05:47:59.409076Z","shell.execute_reply.started":"2024-08-15T05:47:59.375537Z","shell.execute_reply":"2024-08-15T05:47:59.407515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets see if we have any duplicates\n\n# Find Duplicated rows\ndf.duplicated().any()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:48:18.973148Z","iopub.execute_input":"2024-08-15T05:48:18.974382Z","iopub.status.idle":"2024-08-15T05:48:19.000244Z","shell.execute_reply.started":"2024-08-15T05:48:18.974339Z","shell.execute_reply":"2024-08-15T05:48:18.998875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#I'm also curious about the table primary key, is it product_id ?\ndf['product_id'].nunique()\n\n#only 1351 unique prod_id, with 1465 rows, which means some are the products are repeated, however we have not any duplicated rows","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:50:11.415033Z","iopub.execute_input":"2024-08-15T05:50:11.415501Z","iopub.status.idle":"2024-08-15T05:50:11.423896Z","shell.execute_reply.started":"2024-08-15T05:50:11.415467Z","shell.execute_reply":"2024-08-15T05:50:11.422754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#show me rows with duplicated product id \n\nduplicated_products = df[df['product_id'].duplicated(keep=False)]\n\n# Sort by product_id to group duplicates together\nduplicated_products.sort_values('product_id')\n\n#Now I can see what is different in the rows with the same product_id, just to understand the data better","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:50:19.083719Z","iopub.execute_input":"2024-08-15T05:50:19.08424Z","iopub.status.idle":"2024-08-15T05:50:19.125631Z","shell.execute_reply.started":"2024-08-15T05:50:19.084199Z","shell.execute_reply":"2024-08-15T05:50:19.124117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#we've got 1465 rows (prod id) but 1351 unique and 1337 unique prod name, need to check them\n#so I just found out the unique col is product_link col which it means this data table is based on the product_links","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ANy null values?\ndf.isnull().sum().sort_values(ascending = False)\n\n#2 null in rating_count col","metadata":{"execution":{"iopub.status.busy":"2024-08-15T05:15:55.038707Z","iopub.execute_input":"2024-08-15T05:15:55.039118Z","iopub.status.idle":"2024-08-15T05:15:55.05345Z","shell.execute_reply.started":"2024-08-15T05:15:55.039088Z","shell.execute_reply":"2024-08-15T05:15:55.052098Z"},"trusted":true},"execution_count":null,"outputs":[]}]}